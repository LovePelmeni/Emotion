from torch import nn
import torch
import gc
import logging
from tqdm import tqdm
from src.training.datasets import datasets
from src.training.trainers import base

logger = logging.getLogger("fusion_trainer_logger")
file_handler = logging.FileHandler(filename='fusion_trainer_logs.log')
logger.addHandler(file_handler)


class FusionTrainer(base.BaseTrainer):
    """
    Implementation of the Training pipeline
    for training multimodal data fusion layer.
    It leverages the concept of DEC (Deep Embedded Clustering)
    to create a good separation latent space, where embeddings
    will appear sparsed across each given label.

    Parameters:
    -----------
        fusion - nn.Module fusion layer, which accepts
        input image, title and description embeddings.
        optimizer - nn.Module - optimization algorithm for training fusion layer.
        lr_scheduler - nn.Module - LR Scheduler algorithm for tweaking learning rate during training phase.
        loss_function - nn.Module - Loss function to use for fusion training.
        eval_metric - nn.Module - evaluation metric for assessing quality of fusion performance.
        batch_size - batch size to use for dataset
        max_epochs - maximum number of epochs to iterate over during training.

        NOTE:
            evaluation metric should observe similarity of the cluster
            of vectors, generated by the fusion layer.
    """
    def __init__(self, 
        max_epochs: int,
        batch_size: int,
        fusion: nn.Module,
        optimizer: nn.Module,
        loss_function: nn.Module,
        eval_metric: nn.Module,
        train_device: str = 'cpu',
        num_workers: int = 1,
        distributed: bool = False,
        num_replicas: int = 1,
        lr_scheduler: nn.Module = None
    ):
        super(FusionTrainer, self).__init__(**kwargs)
        self.max_epochs: int = max_epochs
        self.batch_size = batch_size
        self.network = fusion.to(self.train_device)
        self.optimizer = optimizer
        self.lr_scheduler = lr_scheduler
        self.loss_function = loss_function
        self.eval_metric = eval_metric
        self.train_device = train_device

    def train(self, train_dataset: datasets.FusionDataset):
        """
        Trains fusion layer to form more sparsed clusters
        of embeddings using train dataset.
        """
        try:
            self.network.train()
            train_loader = super().configure_loader(
                dataset=train_dataset, 
                num_workers=self.num_workers, 
                distributed=self.distributed,
                num_replicas=self.num_replicas if hasattr(self, 'num_replicas') else None
            )
        except(Exception) as err:
            logger.error(err)
            raise RuntimeError(msg='failed to configure training data loader')

        curr_loss = float('inf')
        curr_metric = float('-inf')

        for epoch in range(self.max_epochs):
            epochs_losses = []

            for image_emb, desc_emb, title_emb in tqdm(
                data_loader, 
                desc='epoch=%s;curr_loss=%s;curr_metric=%s;' % (
                    epoch, curr_loss, curr_metric
                )
            ):

                gpu_image_emb = image_emb.to(self.train_device)
                gpu_desc_emb = desc_emb.to(self.train_device)
                gpu_title_emb = title_emb.to(self.train_device)
                
                predicted_embs = self.network.to(self.train_device).forward(
                    embeddings=[
                        gpu_image_emb,
                        gpu_desc_emb, 
                        gpu_title_emb
                    ]
                ).cpu()
                loss = self.loss_function(predictions, labels)
                loss.backward()

                self.optimizer.step()
                
                if self.lr_scheduler is not None:
                    self.lr_scheduler.step()

            curr_loss = min(curr_loss, numpy.mean(epoch_losses))
            
            if self.early_steps >= (epoch):
                curr_metric = self.evaluate(self.early_dataset)
                status = self.early_stopper.step(curr_metric)
                if status: break

    def evaluate(self, validation_dataset: datasets.FusionDataset):
        """
        Evaluates performance of the fusion layer on clustering
        task using validation dataset.
        """
        trues = []
        preds = []
        class_samples: typing.Dict = {}

        with torch.no_grad():

            for image_emb, desc_emb, title_emb, labels in validation_loader:

                gpu_image_emb = image_emb.to(self.train_device)
                gpu_desc_emb = desc_emb.to(self.train_device)
                gpu_title_emb = title_emb.to(self.train_device)

                predictions = self.network.to(self.train_device).forward(
                    embeddings=[
                        gpu_image_emb,
                        gpu_desc_emb,
                        gpu_title_emb,
                    ]
                )
                class_samples[label].append(predictions)
                output_preds.extend(predictions)
        
        eval_metric = (1 / len(class_samples)) * numpy.sum([
            self.evaluation_metric(cluster) 
            for cluster in class_samples
        ])
        return eval_metric